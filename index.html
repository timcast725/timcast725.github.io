<!DOCTYPE html>
<html lang="en">

<head>

	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Portfolio">
	<meta name="author" content="Timothy Castiglia">

	<title>Timothy Castiglia Portfolio</title>
	<link rel="icon" type="image/jpg" href="img/portal.jpg"/>

	<!-- Bootstrap Core CSS -->
	<link href="css/bootstrap.css" rel="stylesheet">

	<!-- Custom CSS -->
	<link href="css/2-col-portfolio.css" rel="stylesheet">
	<link href="css/jquery-ui.css" rel="stylesheet">
	<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
	<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
	<!--[if lt IE 9]>
		<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
		<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
	<![endif]-->

</head>

<body>

	<!-- Navigation -->
	<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
		<div class="container">
			<!-- Brand and toggle get grouped for better mobile display -->
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="navbar-brand">Portfolio</a>
			</div>
			<!-- Collect the nav links, forms, and other content for toggling -->
			<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
				<ul class="nav navbar-nav">
					<li>
						<a data-toggle="modal" data-target="#AboutModal">About</a>
						<div id="AboutModal" class="modal fade" role="dialog">
							<div class="modal-dialog">
								<div class="modal-content">
									<div class="modal-header">
										<button type="button" class="close" data-dismiss="modal">&times;</button>
										<h4 class="modal-title">About</h4>
									</div>
									<img src="img/tim.jpg" alt="" style="display: block; margin: auto;">
									<div class="modal-body">
										<p style="text-indent: 20px;">
											My name is Timothy Castiglia. I received my Bachelor's from Rensselaer Polytechnic Institute in 2017 with a dual major in Computer Science and Computer Systems Engineering. I am currently pursuing my PhD in Computer Science at the same institution with an expected graduation date of May 2023. My work is focused on Federated Learning (FL), a distributed machine learning scenario with several clients and a parameter server collaboratively training a global model for a predictive task. FL algorithms face unique challenges over parallel distributed machine learning algorithms, often used within data centers. In an FL scenario, training data is privately owned by the clients, and the data distribution is imposed on the system. Additionally, FL scenarios often face high communication costs, due to high message latency, power limitations, or network restrictions. My ongoing work is focused around designing FL algorithms to provide client data privacy, accommodate for different FL data distributions, and to be communication-efficient by design. My work provides theoretical convergence analysis of these algorithms, as well as empirical evidence of their improvements over existing FL algorithms.
										</p>
										<br>
										<p>Programming Languages (in order of proficiency)</p>
										<ul>
											<li>Python</li>
											<li>C/C++</li>
											<li>Rust</li>
											<li>Bash</li>
											<li>Java</li>
											<li>Matlab</li>
										</ul>
										<br>
										<p>Operating Systems</p>
										<ul>
											<li>Ubuntu</li>
											<li>CentOS</li>
											<li>Windows</li>
											<li>Raspbian</li>
											<li>Linux Mint</li>
										</ul>
										<br>
										<p>Hobbies</p>
										<ul>
											<li>Hiking</li>
											<li>Heavy Metal</li>
											<li>Traveling</li>
											<li>Guitar</li>
											<li>Bass</li>
										</ul>
									</div>
								</div>
							</div>
						</div>
					</li>
					<li>
						<a data-toggle="modal" data-target="#ContactModal">Contact</a>
						<div id="ContactModal" class="modal fade" role="dialog">
							<div class="modal-dialog">
								<div class="modal-content">
									<div class="modal-header">
										<button type="button" class="close" data-dismiss="modal">&times;</button>
										<h4 class="modal-title">Contact</h4>
									</div>
									<div class="modal-body">
										<h5>Email Address</h5>
										<p style="text-indent: 20px;">castigliatim dot gmail.com</p>
										<br>
										<h5>Phone Number</h5>
										<p style="text-indent: 20px;">(845) 661-6818</p>
									</div>
								</div>
							</div>
						</div>
					</li>
				</ul>
			</div>
			<!-- /.navbar-collapse -->
		</div>
		<!-- /.container -->
	</nav>

	<!-- Page Content -->
	<div class="container">

		<!-- Page Header -->
		<div class="row">
			<div class="col-lg-12">
				<h1 class="page-header">Timothy Castiglia
					<small>Researcher and Software Engineer</small>
				</h1>
			</div>
		</div>
		<!-- /.row -->

		<!-- Projects Row -->
		<div class="row">
			<div class="col-md-6 portfolio-item">
				<a>
					<img class="img-responsive" src="img/ssvfl1.png" alt="http://placehold.it/700x400" data-toggle="modal" data-target="#SS-VFL" height="10%"></a>
				<h3>
					<a data-toggle="modal" data-target="#SS-VFL">Self-Supervised Vertical Federated Learning (2022)</a>
				</h3>
				<p>A novel extension of self-supervised learning to vertical federated learning, where unlabeled data is used to train representation networks and labeled data is used to train a downstream prediction network.</p>
			</div>
			<div id="SS-VFL" class="modal fade" role="dialog">
				<div class="modal-dialog">
					<div class="modal-content">
						<div class="modal-header">
							<button type="button" class="close" data-dismiss="modal">&times;</button>
							<h4 class="modal-title">Self-Supervised Vertical Federated Learning</h4>
						</div>
						<div class="modal-body">
							<p style="text-indent: 20px;">
                            We consider a system where parties store vertically-partitioned data with a partially overlapping sample space, and an aggregation server stores labels on a subset of data samples. Supervised vertical federated learning (VFL) algorithms are limited to training models using only overlapping labeled data, which can lead to poor model performance or bias. Self-supervised learning has been shown to be effective for training on unlabeled data, but the current methods do not generalize to the vertically-partitioned setting. We propose a novel extension of self-supervised learning to VFL (SS-VFL), where unlabeled data is used to train representation networks and labeled data is used to train a downstream prediction network. We present two SS-VFL algorithms: SS-VFL-I is a two-phase algorithm which requires only one round of communication between parties and the server, while SS-VFL-C adds communication rounds to improve model generalization. The design of SS-VFL-C is supported by our analysis of self-supervised learning over vertically-partitioned data. We show that both SS-VFL algorithms can achieve up to 2x higher accuracy than supervised VFL when labeled data is scarce at a significantly reduced communication cost.
							</p>
						<img src="img/ssvfl_model.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/ssvfl_alg1.png" alt="" style="display: block; margin: auto; max-width: 100%">
							<p style="text-indent: 20px;">
                            Both of our proposed algorithms utilize Local Contrastive Learning, presented in Algorithm 2. Each party individually minimizes the following unsupervised objective. The optimization relies on specified positive and negative pairs in the dataset (typically created using data augmentation). The goal of optimization is to train representation networks to place positive pairs close to one another in representation space, and negative pairs far apart. 
							</p>
						<img src="img/ssvfl_alg2.png" alt="" style="display: block; margin: auto; max-width: 100%">
							<p style="text-indent: 20px;">
Above is the pseudo code for SS-VFL-Independent (SS-VFL-I), a natural extension of
contrastive learning to the VFL setting. SS-VFL-I is a communication-efficient 
self-supervised vertical federated learning algorithm.
At the start of training, the parties independently perform local contrastive learning to train their representation networks. 
This is done on local feature sets without communication.
Then, each party computes the 
representations for labeled data and sends these representations to the server.
The server trains its prediction model on these representations,
again without communication.
SS-VFL-I only requires sending representations for all labeled data once,
its communication is equivalent to a single epoch of supervised VFL,
which can be immensely beneficial in situations where communication is limited or costly.
                            </p>
						<img src="img/ssvfl_alg3.png" alt="" style="display: block; margin: auto; max-width: 100%">
							<p style="text-indent: 20px;">
Above is the pseudo-code for SS-VFL Coupled (SS-VFL-C),
a self-supervised vertical federated learning algorithm
that improves representation networks during downstream supervised training 
while maintaining the same communication cost as supervised VFL.
SS-VFL-C trades the communication savings of SS-VFL-I
in order to update representation networks, improving
downstream supervised model performance.
Just as in SS-VFL-I, each party uses local contrastive learning  
to train its representation network.
However, the representation networks are not frozen at this point.
In the second stage of SS-VFL-C, the same procedure as supervised VFL is followed.
The parties share representations with the server, which trains a downstream prediction model. 
Then the server shares partial derivatives with the parties, 
and the parties update their representation networks.
From this, we can see that SS-VFL-C has the same communication
cost as supervised VFL, but with the added benefit of that the representation
networks are pre-trained using unlabeled data.
                            </p>
						<img src="img/ssvfl_plots.png" alt="" style="display: block; margin: auto; max-width: 100%">
							<p style="text-indent: 20px;">
For our experiments, we compare supervised VFL with SS-VFL-I and SS-VFL-C, using different amounts of data in the training set being labeled.
The results of our experiments are shown in the above figures,
where we plot the test accuracy 
for each dataset and labeled data fraction.
The solid lines are the mean of 5 runs, 
while the shaded regions represent the standard deviation.
For the ModelNet10 dataset, we can see at 1% and 5% 
labeled data, both SS-VFL algorithms outperform supervised VFL.
Only at 10% labeled data and more is
supervised VFL able to reach similar accuracies to the SS-VFL algorithms.
We can see that SS-VFL-I and SS-VFL-C perform similarly in all cases, indicating
that LocalCL was able to produce well-separable representations during unsupervised training.
For the ImageNet100 dataset, both SS-VFL algorithms perform similarly 
when 1% of the data is labeled, reaching up to double the accuracy of supervised VFL.
As the amount of labeled data increases, we can see that SS-VFL-C
continues to reach higher test accuracy than the other two algorithms,
providing the best model generalization by utilizing both labeled and unlabeled data
to train party representation networks.
In the case of ImageNet100, LocalCL has more difficulty distinguishing between similar classes.
SS-VFL-C outperforms SS-VFL-I here by utilizing additional communication during 
downstream supervised training, allowing it to refine the representations and improve performance.
                            </p>
						<img src="img/ssvfl_table.png" alt="" style="display: block; margin: auto; max-width: 100%">
							<p style="text-indent: 20px;">
In the above table, we show the communication cost between the parties and the server
for supervised VFL, SS-VFL-I, and SS-VFL-C 
to reach a target test accuracy. 
We can see in Table~\ref{comm.table} that SS-VFL-I has a much smaller communication cost 
than both other algorithms, regardless of the fraction of labeled data.
SS-VFL-C, although requiring more communication, still reduces
overall communication cost to reach target accuracies over supervised VFL
in both datasets.
For scenarios where labeled data is limited, 
both SS-VFL algorithms provide 
immense benefits in communication reduction.
                            </p>
						</div>
					</div>
				</div>
            </div>
			<div class="col-md-6 portfolio-item">
				<a>
					<img class="img-responsive" src="img/flex-vfl.png" alt="http://placehold.it/700x400" data-toggle="modal" data-target="#Flex-VFL">
                </a>
				<h3>
					<a data-toggle="modal" data-target="#Flex-VFL">Flexible Vertical Federated Learning with Heterogeneous Parties (2022)</a>
				</h3>
				<p>Flexible Vertical Federated Learning
                (Flex-VFL): a distributed machine algorithm that trains a smooth,
                non-convex function in a heterogeneous distributed system with vertically
                partitioned data.</p>
			</div>
			<div id="Flex-VFL" class="modal fade" role="dialog">
				<div class="modal-dialog">
					<div class="modal-content">
						<div class="modal-header">
							<button type="button" class="close" data-dismiss="modal">&times;</button>
							<h4 class="modal-title">Flexible Vertical Federated Learning with Heterogeneous Parties</h4>
						</div>
						<img src="img/flex-vfl.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<div class="modal-body">
							<p style="text-indent: 20px;">
                            We propose Flexible Vertical Federated Learning
                            (Flex-VFL), a distributed machine algorithm that trains a smooth,
                            non-convex function in a distributed system with vertically
                            partitioned data. We consider a system with several parties that
                            wish to collaboratively learn a global function. Each party holds
                            a local dataset; the datasets have different features but share
                            the same sample ID space. The parties are heterogeneous in
                            nature: the parties’ operating speeds, local model architectures,
                            and optimizers may be different from one another and, further,
                            they may change over time. To train a global model in such a
                            system, Flex-VFL utilizes a form of parallel block coordinate
                            descent, where parties train a partition of the global model via
                            stochastic coordinate descent. We provide theoretical convergence
                            analysis for Flex-VFL and show that the convergence rate is
                            constrained by the party speeds and local optimizer parameters.
                            We apply this analysis and extend our algorithm to adapt party
                            learning rates in response to changing speeds and local optimizer
                            parameters. Finally, we compare the convergence time of Flex-
                            VFL against synchronous and asynchronous VFL algorithms, as
                            well as illustrate the effectiveness of our adaptive extension.
							</p>
						</div>
						<img src="img/flex-vfl1.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/flex-vfl2.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/flex-vfl3.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/flex-vfl_table.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/flex-vfl_plots1.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/flex-vfl_plots2.png" alt="" style="display: block; margin: auto; max-width: 100%">
					</div>
				</div>
            </div>
			<div class="col-md-6 portfolio-item">
				<a>
					<img class="img-responsive" src="img/cvfl.png" alt="http://placehold.it/700x400" data-toggle="modal" data-target="#CVFL"></a>
				<h3>
					<a data-toggle="modal" data-target="#CVFL">C-VFL: Communication-Efficient Learning with Vertically Partitioned Data (ICML 2022)</a>
				</h3>
				<p>Compressed Vertical Federated Learning (C-VFL): a server and multiple parties collaboratively train a model over vertically-partitioned data utilizing several local iterations and sharing compressed intermediate results periodically. </p>
			</div>
			<div id="CVFL" class="modal fade" role="dialog">
				<div class="modal-dialog">
					<div class="modal-content">
						<div class="modal-header">
							<button type="button" class="close" data-dismiss="modal">&times;</button>
							<h4 class="modal-title">Compressed-VFL: Communication-Efficient Learning with Vertically Partitioned Data</h4>
						</div>
						<div class="modal-body">
							<p style="text-indent: 20px;">
                                We propose Compressed Vertical Federated
                                Learning (C-VFL) for communication-efficient
                                training on vertically partitioned data. In C-VFL,
                                a server and multiple parties collaboratively train
                                a model on their respective features utilizing several
                                local iterations and sharing compressed intermediate
                                results periodically. Our work provides
                                the first theoretical analysis of the effect
                                message compression has on distributed training
                                over vertically partitioned data. We prove convergence
                                of non-convex objectives at a rate of
                                O(1/√T) when the compression error is bounded
                                over the course of training. We provide specific
                                requirements for convergence with common compression
                                techniques, such as quantization and topk
                                sparsification. Finally, we experimentally show
                                compression can reduce communication by over
                                90% without a significant decrease in accuracy
                                over VFL without compression.
							</p>
						</div>
						<img src="img/cvfl_model1.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/cvfl_model2.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/cvfl_alg.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/cvfl_table.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/cvfl_plots.png" alt="" style="display: block; margin: auto; max-width: 100%">
					</div>
				</div>
            </div>
			<div class="col-md-6 portfolio-item">
				<a>
					<img class="img-responsive" src="img/mllsgd.png" alt="http://placehold.it/700x400" data-toggle="modal" data-target="#MLLSGD">
				</a>
				<h3>
					<a data-toggle="modal" data-target="#MLLSGD">Multi-Level Local SGD: Distributed SGD for Heterogeneous Hierarchical Networks (ICLR 2021)</a>
				</h3>
				<p>Multi-Level Local SGD is a distributed stochastic gradient method for learning a smooth, non-convex objective in a multi-level communication network with heterogeneous workers.</p>
			</div>
			<div id="MLLSGD" class="modal fade" role="dialog">
				<div class="modal-dialog">
					<div class="modal-content">
						<div class="modal-header">
							<button type="button" class="close" data-dismiss="modal">&times;</button>
							<h4 class="modal-title">Multi-Level Local SGD: Distributed SGD for Heterogeneous Hierarchical Networks</h4>
						</div>
						<div class="modal-body">
							<p style="text-indent: 20px;">
                                We propose Multi-Level Local SGD, a distributed stochastic gradient method for
                                learning a smooth, non-convex objective in a multi-level communication network
                                with heterogeneous workers. Our network model consists of a set of disjoint subnetworks,
                                with a single hub and multiple workers; further, workers may have different
                                operating rates. The hubs exchange information with one another via a
                                connected, but not necessarily complete, communication network. In our algorithm,
                                sub-networks execute a distributed SGD algorithm, using a hub-and-spoke
                                paradigm, and the hubs periodically average their models with neighboring hubs.
                                We first provide a unified mathematical framework that describes the Multi-Level
                                Local SGD algorithm. We then present a theoretical analysis of the algorithm;
                                our analysis shows the dependence of the convergence error on the worker node
                                heterogeneity, hub network topology, and the number of local, sub-network, and
                                global iterations. We illustrate the effectiveness of our algorithm in a multi-level
                                network with slow workers via simulation-based experiments.
							</p>
						</div>
						<img src="img/mllsgd_alg.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/mllsgd_plots1.png" alt="" style="display: block; margin: auto; max-width: 100%">
						<img src="img/mllsgd_plots2.png" alt="" style="display: block; margin: auto; max-width: 100%">
					</div>
				</div>
			</div>
			<div class="col-md-6 portfolio-item">
				<a>
					<img class="img-responsive" src="img/spectrum.jpg" alt="http://placehold.it/700x400" data-toggle="modal" data-target="#SpectrumModal">
				</a>
				<h3>
					<a data-toggle="modal" data-target="#SpectrumModal">Spectrum Analyzer (2016-2018)</a>
				</h3>
				<p>A web-based Spectrum Analyzer, a tool for electrical engineers. Built with the team from Critical Technologies, Inc. to be a product for telecom companies.</p>
			</div>
			<div id="SpectrumModal" class="modal fade" role="dialog">
				<div class="modal-dialog">
					<div class="modal-content">
						<div class="modal-header">
							<button type="button" class="close" data-dismiss="modal">&times;</button>
							<h4 class="modal-title">Spectrum Analyzer</h4>
						</div>
						<img src="img/spectrum.gif" alt="" style="display: block; margin: auto; max-width: 100%">
						<div class="modal-body">
							<p style="text-indent: 20px;">
								The Spectrum Analyzer was built by the team at Critical Technologies, Inc. for a client. The goal of the product was to be able to view communication signals and determine types of interference remotely. This allowed technicians to diagnose an issue without having to drive out to a basestation. The product saves time and money for telecom companies. 
							</p>
							<p style="text-indent: 20px;">
								The screen above shows three graphs: a spectrum, power vs. time, and &Delta;power vs. time. Typically, the bottom graph would have a flat region in the center. However, there is a spike moving across the band. This is a sweeping frequency that is being injected into the antenna. From this page, a technician could change various settings (Resolution Bandwidth, Span, Max/Min Hold, Averaging, etc.) to understand the interference better, and save the data to be viewed at a later time.
							</p>
							<p style="text-indent: 20px;">
								The software stack for this project was diverse. Starting from the bottom was an FPGA card. The FPGA quickly decoded incoming data, ran complex math calculations on it (Fast Fourier Transforms) and presented them to the operating system. Then, a Kernel Driver, written in C, would pass the data from Kernel space, to User Space. A user space driver, written in C++, would then process the data. The C++ class would either store the data in RAM, save it to file, or stream it to the web. This class was wrapped in the Python program which would take care of the networking for the web. The Python class would stream the data to client-side JavaScript to present to the user on the website. On top of all this, was a Robot that would move fiber connections to different sources of data. The robot motors were controlled by an Arduino, which was passed messages from a Raspberry Pi.
							</p>
							<p style="text-indent: 20px;">
								When the project started, we were given the FPGA, Kernel Driver, and an Arduino controlled Robot. We needed a working system within a month. Two other interns and myself worked tirelessly to build the rest of the software stack. I was forced out of my comfort zone of C++. I had to work on the lower-level, close to the kernel, and at the front-end level when building a website. I learned a great deal in a short amount of time. Together, the three of us produced a functional system at the end of the month.
							</p>
							<p style="text-indent: 20px;">
								This project is still ongoing. My role in the project is software and integration lead. The C++ and Python code that controls the core of the program is my responsibility, but I am familiar with (and have written pieces of) code elsewhere in the stack. In doing so, I can more easily integrate and test the system as a whole when other developers on the team add features. 
							</p>
							<br>
							<p>Software Used</p>
							<ul>
								<li>Twisted Websockets</li>
									<ul><li>TCP library bridging Python and JavaScript.</li></ul>
								<li>Boost-Python</li>
									<ul><li>A method of wrapping a C++ class inside Python.</li></ul>
								<li>GNURadio</li>
									<ul><li>Open Source Software for software-defined radios.</li></ul>
								<li>CentOS 7</li>
								<li>C/C++</li>
								<li>Python</li>
								<li>Bash</li>
								<li>HTML/JS/CSS</li>
							</ul>
							<br>
							<p>Hardware Used</p>
							<ul>
								<li>Custom built robot</li>
									<ul><li>Used for moving fiber optic connections remotely.</li></ul>
								<li>HP ProLiant DL320</li>
									<ul><li>Server used for early development.</li></ul>
								<li>HPE Edgeline EL1000</li>
									<ul><li>Server used for processing at large cell sites.</li></ul>
								<li>Xilinx Zynq UltraScale+ MPSoC<li>
									<ul><li>Board used for processing at smaller cell sites.</li></ul>
								<li>Nallatech FPGA card 385a</li>
							</ul>
						</div>
					</div>
				</div>
            </div>
			<div class="col-md-6 portfolio-item">
				<a>
					<img class="img-responsive" src="img/lamp.jpg" alt="http://placehold.it/700x400" data-toggle="modal" data-target="#LampModal">
				</a>
				<h3>
					<a data-toggle="modal" data-target="#LampModal">Color Changing Lamp (2016)</a>
				</h3>
				<p>Lamp that changes color temperature and intensity based on the ambient light. First place winner at the 2016 New York State Pollution Prevention Institute Student Competition.</p>
			</div>
			<div id="LampModal" class="modal fade" role="dialog">
				<div class="modal-dialog">
					<div class="modal-content">
						<div class="modal-header">
							<button type="button" class="close" data-dismiss="modal">&times;</button>
							<h4 class="modal-title">Color Changing Lamp</h4>
						</div>
						<img src="img/lamp2.jpg" alt="" style="display: block; margin: auto; max-width: 100%">
						<div class="modal-body">
							<p style="text-indent: 20px;">
								Do you find modern compact flourescents and LED lights blinding? Do you miss that soft glow of an incandescent bulb? You're not the only one. And there are more reasons to hate those blinding white LEDs than you may have known. Lights with a lot of blue light in them can affect your sleep cycles. Your circadian rhythm, a.k.a. your body's internal clock, is thrown off because the light reduces your production of melatonin, making you less sleepy. So what is the solution? Do we go back to using incandescents? This a bad idea. 
							</p>
							<p style="text-indent: 20px;">
								Let's say you have a 60 Watt incandescent light bulb. The wattage is a measure of how much energy it will consume over time. In stores currently, you can get an "LED 60 Watt equivalent". Why the "equivalent" in the name? Because LEDs are much more efficient than incandescents. They can use up close to 10 times less power for the same amount of light output. So this 60 Watt equivalent only uses close 6 watts of power. <a href="https://www.1000bulbs.com/product/154564/CM-CMA19-1312-827.html?gclid=CjwKCAjw47bLBRBkEiwABh-PkdnVPHhckert_RJ8V-hCACbHML54jVfy4w2xcJiE3mYKaFcc3prRbRoCzPsQAvD_BwE" target="_blank">Here's an example</a> I found online of a 9 watt LED that is just as bright as your 60 watt incandescent. By switching to LEDs, we cut our power usage ten-fold, reducing how much money spent on electricity, and reducing our footprint on the Earth.
							</p>
							<p style="text-indent: 20px;">
								My partner and I wanted to devise a way to make LEDs not just as nice to look at as incandescents, but take it a step further and have the color and intensity change based on ambient light. During the day, the light is dimmed so it can work with the bright ambient light. It also would match the day with a bright white color for keeping people awake. At night, the light would be brighter, but the color temperature would lower to a calmer yellowish-red to be conducive to someone getting close to sleep. Not only would this help match the human sleep cycle, it would save power during the day by adjusting its intensity automatically.
							</p>
							<p style="text-indent: 20px;">
								Our system was made up of an Arduino microcontroller with a light sensor, RGB LEDs, and a light waveguide. The Arduino would process light from its sensor, and run it through an algorithm to convert the incoming light's color temperature to appropriate RGB values for the LEDs. The LEDs we had were grouped in fours: 1 red, 2 greens, and 1 blue. Three of these groups were placed beneath a waveguide. A waveguide is a flat sheet of plastic. Light enters from the sides, and is reflected such that it appears that the entire sheet of plastic is glowing, taking the piercing bright LEDs and spreading light out more evenly.
							</p>
							<p style="text-indent: 20px;">
								I worked with the Arduino software and the algorithm for converting color temperature to RGB. Color temperature is a measurment of how intense the color is. Lower color temperature is closer to red, and higher color temperature is white and blue. Based on research done previously, I found a large lookup table for what red, green, and blue values matched up with which color temperatures. I used logarithmic regression on the lookup table to approximate the values, and added the equation into the Arduino code. From there, I ran a 12 hour test so that we could determine the power usage throughout the day for our device. My partner and I were able to determine that our device would be much more efficient than an incandescent bulb, as expected, and just about as efficient as a pure white LED. 
							</p>
							<img src="img/regressions.png" alt="" style="display: block; margin: auto; max-width: 100%">
							<p style="text-indent: 20px;">
								We entered our project in the 2016 New York State Pollution Prevention Institute Student Competition. Our application was accepted and we were invited to Clarkson University in Potsdam, New York to have our product judged. The competition mixed both undergraduate and graduate teams (our team being an undergraduate team). We presented our product in front of the judges, and won first place in the competition over both graduate and undergraduate teams (our beautiful trophy shown below, and we also received a $4000 cash prize).
							</p>
							<img src="img/trophy.jpg" alt="" style="display: block; margin: auto; max-width: 100%">
							<br>
							<p>Software Used</p>
							<ul>
								<li>Arduino IDE</li>
								<li>C</li>
							</ul>
							<br>
							<p>Hardware Used</p>
							<ul>
								<li>Arduino Microcontroller</li>
								<li>Adafruit TCS34725 Light Sensor</li>
								<li>Custom RGGB LEDs</li>
								<li>BuckPuck LED Drivers</li>
							</ul>
						</div>
					</div>
				</div>
			</div>
		</div>
		<!-- /.row -->

		<!-- Footer -->
		<footer>
			<div class="row">
				<div class="col-lg-12">
					<p>Timothy Castiglia Portfolio 2022</p>
				</div>
			</div>
			<!-- /.row -->
		</footer>

	</div>
	<!-- /.container -->

	<!-- jQuery -->
	<script src="js/jquery-2.1.4.min.js"></script>
	<script src="js/jquery-ui.js"></script>

	<!-- Bootstrap Core JavaScript -->
	<script src="js/bootstrap.min.js"></script>

</body>

</html>
